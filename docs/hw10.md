# ğŸ§© Market Data Storage and Querying with SQLite3 and Parquet

[market_data_multi.csv â†“](market_data_multi.csv)

[query_tasks.md â†“](query_tasks.md)

[schema.sql â†“](schema.sql)

[tickers.csv â†“](tickers.csv)

## ğŸ§  Overview

Design and implement a Python-based system for ingesting, storing, and querying multi-ticker market data using both **SQLite3** and **Parquet**. You will explore the tradeoffs between relational and columnar storage formats, and demonstrate how each can be used to support financial analytics and trading workflows.

This assignment emphasizes **data engineering fundamentals** in a finance context, including schema design, efficient querying, and format selection based on use case.

## ğŸ¯ Learning Objectives

- Ingest and validate multi-ticker OHLCV data using Python.
- Store structured financial data in both SQLite3 and Parquet formats.
- Design and execute SQL queries for time-series and cross-sectional analysis.
- Compare performance and storage tradeoffs between relational and columnar formats.
- Understand the role of databases in trading systems and financial research.

## ğŸ“‹ Task Specifications

## ğŸ—‚ï¸ Data Ingestion and Validation

**Problem:** Load and validate multi-ticker market data from CSV.

**Expectations:**

- Load market_data_multi.csv using pandas.
- Validate:
  - No missing timestamps or prices.
  - All tickers listed in tickers.csv are present.
- Normalize column names and ensure consistent datetime formatting.

## ğŸ”¨ SQLite3 Storage and Querying

**Problem:** Store and query multi-ticker OHLCV data using SQLite3.

**Expectations:**

- Use schema.sql to define a normalized schema with:
  - tickers table (ticker_id, symbol)
  - prices table (timestamp, ticker_id, open, high, low, close, volume)
- Insert validated data into the database.
- Write SQL queries to:
  - Retrieve all data for a given ticker and date range.
  - Calculate average daily volume per ticker.
  - Identify the top 3 tickers by return over a given week.
  - Find the first and last trade price for each ticker per day.

## ğŸ§± Parquet Storage and Querying

**Problem:** Store and query the same dataset using Parquet.

**Expectations:**

- Convert the dataset to Parquet format using pandas or pyarrow.
- Partition the file by ticker symbol.
- Load and query the Parquet data to:
  - Retrieve all data for a given ticker and date range.
  - Compute rolling 5-day volatility for each ticker.
  - Compare Parquet query performance to SQLite3 for the same task.

## ğŸ“Š Format Comparison and Use Case Analysis

**Problem:** Evaluate the tradeoffs between SQLite3 and Parquet for financial data storage.

**Expectations:**

- Compare:
  - File size
  - Query speed (for at least two representative queries)
  - Ease of integration with analytics workflows
- Discuss:
  - When to use SQLite3 vs Parquet in trading systems.
  - How each format supports backtesting, live trading, and research.

## âœ… Unit Tests

- Validate schema creation and data insertion.
- Confirm SQL query outputs match expected results.
- Verify Parquet partitioning and data integrity.

## ğŸ“¦ Deliverables

ğŸ‘‰ Please share your GitHub with your TAs:

Jenn: jcolli5158

Hunter: hyoung3

| File | Description |
|------|-------------|
| data_loader.py | Loads and validates multi-ticker CSV data |
| sqlite_storage.py | Creates schema, inserts data, and runs SQL queries |
| parquet_storage.py | Converts data to Parquet and performs queries |
| query_tasks.md | SQL and Parquet query results and performance notes |
| comparison.md | Format comparison and use case discussion |
| market_data.db | SQLite3 database file |
| market_data/ | Parquet directory with partitioned files |
| tests/ | Unit tests for ingestion and querying |
| README.md | Setup instructions and module descriptions |